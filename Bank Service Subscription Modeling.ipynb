{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Information:\n",
    "\n",
    "### Team Member 1:\n",
    "* UNI: sf2796\n",
    "* Name: Sicong Fang\n",
    "\n",
    
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step0 - Import Libraries, Load Data [0 points]\n",
    "\n",
    "This is the basic step where you can load the data and create train and test sets for internal validation as per your convinience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# List of Missing Values\n",
    "NA = ['nonexistent', 'unknown']\n",
    "\n",
    "# Load Data and Holdout Set\n",
    "data = pd.read_csv('data/data.csv', na_values=NA)\n",
    "X_holdout = pd.read_csv('data/holdout.csv', na_values=NA)\n",
    "\n",
    "# Split Data into Input and Output Variables\n",
    "X = data.drop(['duration', 'subscribed'], axis=1)\n",
    "y = data.subscribed.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "# Split Data into Random Training and Testing Subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "# Extract ID from Holdout Set\n",
    "ID = X_holdout.ID\n",
    "X_holdout = X_holdout.drop(['ID', 'duration'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1 - Exploration and Preparation [10 points]\n",
    "\n",
    "In this step, we expect you to look into the data and try to understand it before modeling. This understanding may lead to some basic data preparation steps which are common across the two model sets required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education</th>\n",
       "      <th>credit_default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>prev_outcomes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>mon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>thu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            job marital_status          education credit_default housing loan  \\\n",
       "0   blue-collar        married           basic.9y             no     yes   no   \n",
       "1  entrepreneur        married                NaN             no      no   no   \n",
       "2    unemployed        married           basic.9y             no     yes  yes   \n",
       "3       retired       divorced           basic.4y             no     yes   no   \n",
       "4  entrepreneur        married  university.degree            NaN     yes   no   \n",
       "\n",
       "    contact month day_of_week prev_outcomes  \n",
       "0  cellular   apr         mon           NaN  \n",
       "1  cellular   may         wed           NaN  \n",
       "2  cellular   nov         fri           NaN  \n",
       "3  cellular   may         wed           NaN  \n",
       "4  cellular   jul         thu           NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical Variables\n",
    "X[X.columns[X.dtypes == 'object']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>prev_days</th>\n",
       "      <th>prev_contacts</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.695118</td>\n",
       "      <td>92.698705</td>\n",
       "      <td>-46.727552</td>\n",
       "      <td>1.345160</td>\n",
       "      <td>5097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.767159</td>\n",
       "      <td>92.914878</td>\n",
       "      <td>-46.313088</td>\n",
       "      <td>1.314499</td>\n",
       "      <td>5100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.100365</td>\n",
       "      <td>93.423076</td>\n",
       "      <td>-41.904559</td>\n",
       "      <td>4.003471</td>\n",
       "      <td>5193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.771314</td>\n",
       "      <td>93.672814</td>\n",
       "      <td>-46.045500</td>\n",
       "      <td>1.261668</td>\n",
       "      <td>5100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.458103</td>\n",
       "      <td>94.296285</td>\n",
       "      <td>-42.455877</td>\n",
       "      <td>5.152077</td>\n",
       "      <td>5233.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  campaign  prev_days  prev_contacts  emp_var_rate  cons_price_idx  \\\n",
       "0  41.0       2.0        999              0     -1.695118       92.698705   \n",
       "1  46.0       2.0        999              0     -1.767159       92.914878   \n",
       "2  56.0       1.0        999              0     -0.100365       93.423076   \n",
       "3  89.0       4.0        999              0     -1.771314       93.672814   \n",
       "4  34.0       8.0        999              0      1.458103       94.296285   \n",
       "\n",
       "   cons_conf_idx  euribor3m  nr_employed  \n",
       "0     -46.727552   1.345160       5097.0  \n",
       "1     -46.313088   1.314499       5100.0  \n",
       "2     -41.904559   4.003471       5193.0  \n",
       "3     -46.045500   1.261668       5100.0  \n",
       "4     -42.455877   5.152077       5233.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continuous Variables\n",
    "X[X.columns[X.dtypes != 'object']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode Categorical Variables as One-Hot\n",
    "X = pd.get_dummies(X)\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "X_holdout = pd.get_dummies(X_holdout)\n",
    "\n",
    "# Insert Missing Columns\n",
    "if X_test.shape[1] == 54:\n",
    "    X_test.insert(31, 'credit_default_yes', 0)\n",
    "if X_holdout.shape[1] == 54:\n",
    "    X_holdout.insert(31, 'credit_default_yes', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 - ModelSet1 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set1:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. Any classification algorithm covered in class apart from tree-based models can be tested here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC Score: 0.793\n",
      "   Test ROC AUC Score: 0.783\n"
     ]
    }
   ],
   "source": [
    "# Model 01 – Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'logisticregression__C': np.logspace(-1, 1, 7)}\n",
    "pipe = make_pipeline(RandomUnderSampler(), StandardScaler(), LogisticRegression(class_weight='balanced',\n",
    "                                                                                random_state=0))\n",
    "model_01 = GridSearchCV(pipe, param_grid, cv=5)\n",
    "# model_01.fit(X_train, y_train)\n",
    "\n",
    "# score_01 = np.mean(cross_val_score(model_01, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(score_01))\n",
    "\n",
    "# y_pred = model_01.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC Score: 0.750\n",
      "   Test ROC AUC Score: 0.748\n"
     ]
    }
   ],
   "source": [
    "# # Model 02 – Support Vector Machines\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# param_grid = {'svc__C': np.logspace(-2, 2, 5)}\n",
    "# pipe = make_pipeline(RandomUnderSampler(), StandardScaler(), SelectKBest(), SVC(probability=True,\n",
    "#                                                                                 class_weight='balanced',\n",
    "#                                                                                 random_state=0))\n",
    "# model_02 = GridSearchCV(pipe, param_grid, cv=5)\n",
    "# model_02.fit(X_train, y_train)\n",
    "\n",
    "# score_02 = np.mean(cross_val_score(model_02, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(score_02))\n",
    "\n",
    "# y_pred = model_02.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC Score: 0.793\n",
      "   Test ROC AUC Score: 0.782\n"
     ]
    }
   ],
   "source": [
    "# Model 03 – Neural Networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_03 = make_pipeline(RandomUnderSampler(), StandardScaler(), MLPClassifier(hidden_layer_sizes=(200, ),\n",
    "                                                                               activation='logistic',\n",
    "                                                                               solver='sgd',\n",
    "                                                                               learning_rate='adaptive',\n",
    "                                                                               random_state=0))\n",
    "# model_03.fit(X_train, y_train)\n",
    "\n",
    "# score_03 = np.mean(cross_val_score(model_03, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(score_03))\n",
    "\n",
    "# y_pred = model_03.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC Score: 0.792\n",
      "   Test ROC AUC Score: 0.783\n"
     ]
    }
   ],
   "source": [
    "# Model 04 – Linear Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "model_04 = make_pipeline(RandomUnderSampler(), StandardScaler(), LinearDiscriminantAnalysis(solver='eigen',\n",
    "                                                                                            shrinkage='auto'))\n",
    "# model_04.fit(X_train, y_train)\n",
    "\n",
    "# score_04 = np.mean(cross_val_score(model_04, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(score_04))\n",
    "\n",
    "# y_pred = model_04.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC Score: 0.781\n",
      "   Test ROC AUC Score: 0.768\n"
     ]
    }
   ],
   "source": [
    "# # Model 05 – Quadratic Discriminant Analysis\n",
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# param_grid = {'quadraticdiscriminantanalysis__reg_param': np.linspace(0, 1, 9)}\n",
    "# pipe = make_pipeline(RandomUnderSampler(), StandardScaler(), QuadraticDiscriminantAnalysis())\n",
    "# model_05 = GridSearchCV(pipe, param_grid, cv=5)\n",
    "# model_05.fit(X_train, y_train)\n",
    "\n",
    "# score_05 = np.mean(cross_val_score(model_05, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(score_05))\n",
    "\n",
    "# y_pred = model_05.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3 - ModelSet2 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set2:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. We encourage you to try decition tree, random forest and gradient boosted tree methods here and pick the one which you think works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC Score: 0.798\n",
      "   Test ROC AUC Score: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Model 06 – XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_06 = XGBClassifier(max_depth=5,\n",
    "                         learning_rate=0.03,\n",
    "                         n_estimators=150,\n",
    "                         gamma=3,\n",
    "                         seed=0)\n",
    "# model_06.fit(X_train, y_train)\n",
    "\n",
    "# score_06 = np.mean(cross_val_score(model_06, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(score_06))\n",
    "\n",
    "# y_pred = model_06.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC Score: 0.791\n",
      "   Test ROC AUC Score: 0.783\n"
     ]
    }
   ],
   "source": [
    "# # Model 07 – Random Forest\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model_07 = make_pipeline(RandomUnderSampler(), RandomForestClassifier(n_estimators=150,\n",
    "#                                                                       criterion='entropy',\n",
    "#                                                                       max_depth=5,\n",
    "#                                                                       min_samples_split=500,\n",
    "#                                                                       min_samples_leaf=50,\n",
    "#                                                                       random_state=0,\n",
    "#                                                                       class_weight='balanced_subsample'))\n",
    "# model_07.fit(X_train, y_train)\n",
    "\n",
    "# score_07 = np.mean(cross_val_score(model_07, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(score_07))\n",
    "\n",
    "# y_pred = model_07.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC Score: 0.795\n",
      "   Test ROC AUC Score: 0.792\n"
     ]
    }
   ],
   "source": [
    "# Model 08 – Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model_08 = make_pipeline(RandomUnderSampler(), ExtraTreesClassifier(n_estimators=150,\n",
    "                                                                    criterion='entropy',\n",
    "                                                                    max_depth=8,\n",
    "                                                                    min_samples_split=300,\n",
    "                                                                    min_samples_leaf=15,\n",
    "                                                                    random_state=0,\n",
    "                                                                    class_weight='balanced_subsample'))\n",
    "# model_08.fit(X_train, y_train)\n",
    "\n",
    "# score_08 = np.mean(cross_val_score(model_08, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(score_08))\n",
    "\n",
    "# y_pred = model_08.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC Score: 0.780\n",
      "   Test ROC AUC Score: 0.776\n"
     ]
    }
   ],
   "source": [
    "# # Model 09 – Gradient Boosting\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# model_09 = make_pipeline(RandomUnderSampler(), GradientBoostingClassifier(learning_rate=0.1,\n",
    "#                                                                           n_estimators=250,\n",
    "#                                                                           max_depth=5,\n",
    "#                                                                           min_samples_split=500,\n",
    "#                                                                           min_samples_leaf=50,\n",
    "#                                                                           max_features='auto',\n",
    "#                                                                           random_state=0))\n",
    "# model_09.fit(X_train, y_train)\n",
    "\n",
    "# score_09 = np.mean(cross_val_score(model_09, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(score_09))\n",
    "\n",
    "# y_pred = model_09.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC Score: 0.790\n",
      "   Test ROC AUC Score: 0.784\n"
     ]
    }
   ],
   "source": [
    "# # Model 10 – AdaBoost\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# model_10 = make_pipeline(RandomUnderSampler(), AdaBoostClassifier(n_estimators=150,\n",
    "#                                                                   learning_rate=0.1,\n",
    "#                                                                   random_state=0))\n",
    "# model_10.fit(X_train, y_train)\n",
    "\n",
    "# score_10 = np.mean(cross_val_score(model_10, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(score_10))\n",
    "\n",
    "# y_pred = model_10.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4 - Ensemble [20 points + 10 Bonus points]\n",
    "\n",
    "In this step, we expect you to use the models created before and create new predictions. You should definitely try poor man's stacking but we encourage you to think of different ensemble techniques as well. We will judge your creativity and improvement in model performance using ensemble models and you can potentially earn 10 bonus points here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:   0%\n",
      "Progress:  10%\n",
      "Progress:  30%\n",
      "Progress:  40%\n",
      "Progress:  60%\n",
      "Progress:  80%\n"
     ]
    }
   ],
   "source": [
    "# Select Final Models\n",
    "print('Progress:   0%')\n",
    "model_01.fit(X, y); print('Progress:  10%')  # Logistic Regression\n",
    "# model_02.fit(X, y); print('Progress:  20%')  # Support Vector Machines\n",
    "model_03.fit(X, y); print('Progress:  30%')  # Neural Networks\n",
    "model_04.fit(X, y); print('Progress:  40%')  # Linear Discriminant Analysis\n",
    "# model_05.fit(X, y); print('Progress:  50%')  # Quadratic Discriminant Analysis\n",
    "model_06.fit(X, y); print('Progress:  60%')  # XGBoost\n",
    "# model_07.fit(X, y); print('Progress:  70%')  # Random Forests\n",
    "model_08.fit(X, y); print('Progress:  80%')  # Extra Trees\n",
    "# model_09.fit(X, y); print('Progress:  90%')  # Gradient Boosting\n",
    "# model_10.fit(X, y); print('Progress: 100%')  # AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC Score: 0.797\n",
      "   Test ROC AUC Score: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Model 01 – Averaging\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# estimators = [('01', model_01), ('06', model_06),\n",
    "#               ('02', model_02), ('07', model_07),\n",
    "#               ('03', model_03), ('08', model_08),\n",
    "#               ('04', model_04), ('09', model_09),\n",
    "#               ('05', model_05), ('10', model_10)]\n",
    "\n",
    "estimators = [('01', model_01), ('03', model_03), ('04', model_04), ('06', model_06), ('08', model_08)]\n",
    "\n",
    "# weights = [score_01, score_02, score_03, score_04, score_05,\n",
    "#            score_06, score_07, score_08, score_09, score_10]\n",
    "\n",
    "weights = [score_01, score_03, score_04, score_06, score_08]\n",
    "\n",
    "ensemble_01 = VotingClassifier(estimators, voting='soft', weights=weights)\n",
    "# ensemble_01.fit(X_train, y_train)\n",
    "\n",
    "en_score_01 = np.mean(cross_val_score(ensemble_01, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(en_score_01))\n",
    "\n",
    "# y_pred = ensemble_01.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC Score: 0.796\n",
      "   Test ROC AUC Score: 0.788\n"
     ]
    }
   ],
   "source": [
    "# # Ensemble Model 02 – Stacking\n",
    "# from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "# # classifiers = [model_01, model_02, model_03, model_04, model_05,\n",
    "# #                model_06, model_07, model_08, model_09, model_10]\n",
    "\n",
    "# classifiers = [model_03, model_04, model_06, model_08]\n",
    "\n",
    "# meta_classifier = model_01\n",
    "\n",
    "# ensemble_02 = StackingClassifier(classifiers, meta_classifier, use_probas=True)\n",
    "# ensemble_02.fit(X_train, y_train)\n",
    "\n",
    "# en_score_02 = np.mean(cross_val_score(ensemble_02, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(en_score_02))\n",
    "\n",
    "# y_pred = ensemble_02.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC Score: 0.795\n",
      "   Test ROC AUC Score: 0.790\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Model 03 – Easy Ensemble with Decision Trees\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def easy_ensemble(estimator, n_estimators=100):\n",
    "    estimators = []\n",
    "    for i in range(n_estimators):\n",
    "        model = clone(estimator)\n",
    "        if hasattr(model, 'random_state'):\n",
    "            model.random_state = i\n",
    "        pipe = make_pipeline(RandomUnderSampler(random_state=i, replacement=True), model)\n",
    "        estimators.append(('model_i'.format(i), pipe))\n",
    "    return VotingClassifier(estimators, voting='soft')\n",
    "\n",
    "ensemble_03 = easy_ensemble(DecisionTreeClassifier(criterion='entropy',\n",
    "                                                   max_features='auto',\n",
    "                                                   max_depth=8,\n",
    "                                                   min_samples_split=500,\n",
    "                                                   min_samples_leaf=50,\n",
    "                                                   class_weight='balanced'), n_estimators=100)\n",
    "# ensemble_03.fit(X_train, y_train)\n",
    "\n",
    "en_score_03 = np.mean(cross_val_score(ensemble_03, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(en_score_03))\n",
    "\n",
    "# y_pred = ensemble_03.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Ensemble Model 04 – Random Oversampling with Grid Search for Gradient Boosting\n",
    "\n",
    "# param_grid = {'gradientboostingclassifier__n_estimators': range(100, 300, 21),\n",
    "#               'gradientboostingclassifier__max_depth': range(2, 20, 19),\n",
    "#               'gradientboostingclassifier__max_features': ['log2', 'sqrt'],\n",
    "#               'gradientboostingclassifier__learning_rate': [0.01, 0.02, 0.04, 0.05, 0.08, 0.10, 0.20]}\n",
    "# pipe = make_pipeline(RandomOverSampler(), GradientBoostingClassifier(random_state=0))\n",
    "\n",
    "# ensemble_04 = GridSearchCV(pipe, param_grid, cv=5, refit=True)\n",
    "# ensemble_04.fit(X_train, y_train)\n",
    "\n",
    "# en_score_04 = np.mean(cross_val_score(ensemble_04, X_train, y_train, scoring='roc_auc', cv=7))\n",
    "# print('Average ROC AUC Score: {:.3f}'.format(en_score_04))\n",
    "\n",
    "# y_pred = ensemble_04.predict_proba(X_test)[:, 1]\n",
    "# print('   Test ROC AUC Score: {:.3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure Average Ensemble ROC AUC Score Is at Least 75%\n",
    "assert np.mean([en_score_01, en_score_03]) >= 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Train Ensembles for Submission\n",
    "# ensemble_01.fit(X, y);\n",
    "# ensemble_02.fit(X, y);\n",
    "# ensemble_03.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Output Submissions for Kaggle\n",
    "# subscribed_01 = ensemble_01.predict_proba(X_holdout)[:, 1]\n",
    "# subscribed_02 = ensemble_02.predict_proba(X_holdout)[:, 1]\n",
    "# subscribed_03 = ensemble_03.predict_proba(X_holdout)[:, 1]\n",
    "\n",
    "# submission_01 = pd.DataFrame({'ID': ID, 'subscribed': subscribed_01})\n",
    "# submission_02 = pd.DataFrame({'ID': ID, 'subscribed': subscribed_02})\n",
    "# submission_03 = pd.DataFrame({'ID': ID, 'subscribed': subscribed_03})\n",
    "\n",
    "# submission_01.to_csv('data/submission_01.csv', index=False)\n",
    "# submission_02.to_csv('data/submission_02.csv', index=False)\n",
    "# submission_03.to_csv('data/submission_03.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
